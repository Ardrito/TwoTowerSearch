{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06da8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import torch.optim as optim\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d39a1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "marco_dataset = load_dataset('ms_marco', 'v1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af821ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'rb') as file:\n",
    "    tokenizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1718ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(word, tokenizer=tokenizer):\n",
    "    if word in tokenizer.keys():\n",
    "        return tokenizer[word]\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7c23a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_tokens = {}\n",
    "def inverse(tokenizer):\n",
    "    for token in tokenizer:\n",
    "\n",
    "        inverse_tokens[tokenizer[token]] = token\n",
    "inverse(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64e54c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_tokenize(word,inverse_tokens=inverse_tokens):\n",
    "    if (int(word) == 0):\n",
    "        return None\n",
    "    return inverse_tokens[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beba1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_marco_text = []\n",
    "for split in marco_dataset:\n",
    "    tokenized_sample = []\n",
    "    for sample in marco_dataset[split]:\n",
    "        for words in (sample['passages']['passage_text']):\n",
    "            words_ = re.sub(r'[^a-zA-Z-\\s]', '', words)\n",
    "            words_ = (words_.lower().split(\" \"))\n",
    "            for word in words_:\n",
    "                tokenized_marco_text.append(tokenize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee035461",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenized_marco/tokenized_marco_text\",\"wb\") as file:\n",
    "    pickle.dump(tokenized_marco_text,file)\n",
    "\n",
    "with open(\"tokenized_marco/tokenized_marco_text\",\"rb\") as file:\n",
    "    tokenized_marco_text = pickle.load(file)  #To load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d788778",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embed_train_dataset(Dataset):\n",
    "    def __init__(self, words, window=2):\n",
    "        self.data = words\n",
    "        self.window = window\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)-4\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx+self.window    \n",
    "        sent = self.data[max(0,idx-self.window):min(idx+self.window+1,len(self.data))]    \n",
    "        if len(sent) > 1:\n",
    "            rand_idx = random.randint(0,len(sent)-1)\n",
    "            target = sent[rand_idx]\n",
    "            del sent[rand_idx]\n",
    "            #print (sent)\n",
    "            tokenized = torch.tensor(sent)\n",
    "            #print (tokenized)\n",
    "            \n",
    "            return tokenized, torch.tensor(target)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a93d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[   1, 4582,  277,   38]]), tensor([15])]\n"
     ]
    }
   ],
   "source": [
    "dataset = embed_train_dataset(tokenized_marco_text)\n",
    "dataloader = DataLoader(dataset, batch_size=1,shuffle=True)\n",
    "\n",
    "for data in dataloader:\n",
    "    print (data)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84d0021e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76288"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc8aaba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size = 76288, embedding_dim = 256):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size,embedding_dim)   \n",
    "        self.lin = nn.Linear(embedding_dim,vocab_size)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        # print (inputs)\n",
    "        # print(inputs.shape)\n",
    "        embs = self.embed(inputs)\n",
    "        embs = embs.mean(dim=1)\n",
    "        out = self.lin(embs)\n",
    "        probs = F.log_softmax(out,dim=1)\n",
    "        return probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7762aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "    number_epochs = 5\n",
    "\n",
    "    #train_wiki, val_wiki = train_test_split(words)\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print (device)\n",
    "    dataset = embed_train_dataset(tokenized_marco_text)\n",
    "    dataloader = DataLoader(dataset, batch_size=128,shuffle=True)\n",
    "    \n",
    "    model = CBOW().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "    best_loss = 100000000000000.0\n",
    "    for epoch in range(number_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for X,Y in tqdm(dataloader):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(X)\n",
    "            loss = F.cross_entropy(pred,Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss\n",
    "            #print (loss.item())\n",
    "        epoch_loss = epoch_loss/len(dataloader)\n",
    "        print(f\"Epoch: {epoch}/{number_epochs}, loss: {epoch_loss} \")\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), f'checkpoints/best.pt')\n",
    "            print(f\"Model improved. Saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba5ad894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/467576 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     16\u001b[39m model.train()\n\u001b[32m     17\u001b[39m epoch_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mY\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLX/week_2/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLX/week_2/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLX/week_2/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:763\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    764\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLX/week_2/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:698\u001b[39m, in \u001b[36m_BaseDataLoaderIter._next_index\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLX/week_2/.venv/lib/python3.12/site-packages/torch/utils/data/sampler.py:344\u001b[39m, in \u001b[36mBatchSampler.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    342\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m [*batch_droplast]\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     batch = [*itertools.islice(sampler_iter, \u001b[38;5;28mself\u001b[39m.batch_size)]\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m batch:\n\u001b[32m    346\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m batch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLX/week_2/.venv/lib/python3.12/site-packages/torch/utils/data/sampler.py:198\u001b[39m, in \u001b[36mRandomSampler.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_samples // n):\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandperm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m.tolist()\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m torch.randperm(n, generator=generator).tolist()[\n\u001b[32m    200\u001b[39m         : \u001b[38;5;28mself\u001b[39m.num_samples % n\n\u001b[32m    201\u001b[39m     ]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
